import os
import sys
import asyncio
import psutil
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
import numpy as np

from telegram import Update, BotCommand
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from telegram.error import Conflict

from openai import OpenAI
from chromadb import Client, Settings
from chromadb.utils import embedding_functions

# –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
EMBEDDING_DIM = 768
# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã:
# EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
# EMBEDDING_DIM = 384
# EMBEDDING_MODEL = "sentence-transformers/distiluse-base-multilingual-cased-v2"
# EMBEDDING_DIM = 512

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
load_dotenv()
TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")

# –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=EMBEDDING_MODEL)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
def normalize_embedding(embedding):
    """Normalize embedding to unit length (L2 norm = 1)."""
    embedding = np.array(embedding)
    norm = np.linalg.norm(embedding)
    if norm > 0:
        return (embedding / norm).tolist()
    return embedding.tolist()

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB ---
database = Client(settings=Settings(
    persist_directory="./db",
    allow_reset=True,
    is_persistent=True  # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∫–ª—é—á–µ–Ω–æ
))

collection = database.get_or_create_collection(
    name="docs",
    embedding_function=embedding_func,
    metadata={"hnsw:space": "cosine"}  # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º —Ç–∏–ø —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
)

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama ---
client = OpenAI(
    base_url='http://localhost:11434/v1',
    api_key='ollama'  # –§–∏–∫—Ç–∏–≤–Ω—ã–π –∫–ª—é—á (–Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
)

async def llama_response(prompt: str) -> str:
    """–ó–∞–ø—Ä–æ—Å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π Llama 3"""
    try:
        response = client.chat.completions.create(
            model="llama3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {str(e)}"

async def rephrase_query(query: str) -> str:
    """–ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –≤ –∫—Ä–∞—Ç–∫–∏–π, –ø—Ä—è–º–æ–π –∏ —è—Å–Ω—ã–π –≤–æ–ø—Ä–æ—Å"""
    prompt = (
        "–ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å –≤ –∫—Ä–∞—Ç–∫–∏–π –∏ —è—Å–Ω—ã–π –≤–æ–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ—Ö—Ä–∞–Ω—è—è –µ–≥–æ –∏—Å—Ö–æ–¥–Ω—ã–π —Å–º—ã—Å–ª. "
        "–ò—Å–ø–æ–ª—å–∑—É–π –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∑—ã–∫, –ø–æ–¥—Ö–æ–¥—è—â–∏–π –¥–ª—è –¥–µ–ª–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –∏ –∏–∑–±–µ–≥–∞–π –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–ª—é–¥–∏' –≤–º–µ—Å—Ç–æ '—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏') –∏–ª–∏ –ª–∏—à–Ω–∏—Ö —Ñ—Ä–∞–∑. "
        "–£–±–µ–¥–∏—Å—å, —á—Ç–æ —Ç–µ–º–∞—Ç–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ü–µ–ª—å –∫–æ–º–ø–∞–Ω–∏–∏, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤) –æ—Å—Ç–∞–µ—Ç—Å—è –Ω–µ–∏–∑–º–µ–Ω–Ω–æ–π. –í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\n"
        "–ü—Ä–∏–º–µ—Ä—ã:\n"
        "1. '–ö–∞–∫–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—Ü –≤ –≤–∞—à–µ–º –∫–æ–ª–ª–µ–∫—Ç–∏–≤–µ?' ‚Üí '–°–∫–æ–ª—å–∫–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –≤ –≤–∞—à–µ–π –∫–æ–º–ø–∞–Ω–∏–∏?'\n"
        "2. '–ö–∞–∫–æ–≤–∞ —Ü–µ–ª—å –≤–∞—à–µ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏?' ‚Üí '–ö–∞–∫–æ–≤–∞ —Ü–µ–ª—å –≤–∞—à–µ–π –∫–æ–º–ø–∞–Ω–∏–∏?'\n"
        "3. '–ö—Ç–æ –ª—É—á—à–∏–π —Ä–∞–±–æ—Ç–Ω–∏–∫ –º–µ—Å—è—Ü–∞?' ‚Üí '–ö—Ç–æ –ª—É—á—à–∏–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –º–µ—Å—è—Ü–∞ –≤ –≤–∞—à–µ–π –∫–æ–º–ø–∞–Ω–∏–∏?'\n"
        "4. '–ö–∞–∫ –¥–∞–≤–Ω–æ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤–∞—à–∞ —Ñ–∏—Ä–º–∞?' ‚Üí '–ö–∞–∫–æ–≤ –≤–æ–∑—Ä–∞—Å—Ç –≤–∞—à–µ–π –∫–æ–º–ø–∞–Ω–∏–∏?'\n"
        "5. '–ö–∞–∫–æ–µ –∏–º—è –Ω–æ—Å–∏—Ç –≤–∞—à–∞ –∫–æ–Ω—Ç–æ—Ä–∞?' ‚Üí '–ö–∞–∫ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è –≤–∞—à–∞ –∫–æ–º–ø–∞–Ω–∏—è?'\n"
        f"–ó–∞–ø—Ä–æ—Å: '{query}'"
    )
    response = await llama_response(prompt)
    #print(f"Rephrased query: '{query}' -> '{response}'")
    return response


# --- –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ Telegram ---
async def set_commands(app):
    commands = [
        BotCommand("start", "–ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã"),
        BotCommand("search", "–ü–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"),
        BotCommand("save_on", "–†–µ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–≤–∫–ª)"),
        BotCommand("save_off", "–†–µ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–≤—ã–∫–ª)"),
        BotCommand("delete", "–£–¥–∞–ª–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ ID")
    ]
    await app.bot.set_my_commands(commands)

async def post_init(application):
    """–§—É–Ω–∫—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞"""
    await set_commands(application)

async def start(update: Update, context):
    await update.message.reply_text(
        "ü§ñ –Ø –±–æ—Ç —Å LLama AI. –ù–∞–ø–∏—à–∏ –º–Ω–µ —á—Ç–æ-–Ω–∏–±—É–¥—å!"
    )

async def save_mode_on(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ê–∫—Ç–∏–≤–∏—Ä—É–µ—Ç —Ä–µ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    context.user_data["save_mode"] = True
    await update.message.reply_text("‚úÖ –†–µ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∫–ª—é—á—ë–Ω. –û—Ç–ø—Ä–∞–≤—å —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å.")

async def save_mode_off(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç —Ä–µ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    context.user_data["save_mode"] = False
    await update.message.reply_text("‚ùå –†–µ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–∫–ª—é—á—ë–Ω. –¢–µ–ø–µ—Ä—å —è –æ–±—ã—á–Ω—ã–π —á–∞—Ç-–±–æ—Ç.")

async def search_docs(update: Update, context):
    """–ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –±–ª–∏–∂–∞–π—à–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∫ –∑–∞–ø—Ä–æ—Å—É"""
    if not context.args:
        await update.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å: /search <–≤–∞—à –∑–∞–ø—Ä–æ—Å>")
        return
    
    query = " ".join(context.args)
    query = await rephrase_query(query)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞
    query_embedding = normalize_embedding(embedding_func([query])[0])
    norm = np.linalg.norm(query_embedding)
    #print(f"Norm of query embedding for '{query[:50]}...': {norm}")
    
    # –ò—â–µ–º 5 —Å–∞–º—ã—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=5,
        include=["documents", "metadatas", "distances"]
    )
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    # for dist in results["distances"][0]:
    #     print(f"Distance: {dist}")
    #     if dist < 0 or dist > 2:
    #         print(f"Warning: distance {dist} is out of expected range for cosine distance")
    
    if not results["documents"]:
        await update.message.reply_text("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ üòî")
        return
    
    response = ["üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞:"]
    for i, (doc, meta, dist, doc_id) in enumerate(zip(
        results["documents"][0],
        results["metadatas"][0],
        results["distances"][0],
        results["ids"][0]
    ), 1):
        user = meta.get("user", "unknown")
        similarity = max(0, min(1, 1 - dist))  # –ó–∞–∂–∏–º–∞–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –≤ [0, 1]
        response.append(
            f"{i}. ID: `{doc_id}`\n"
            f"   üë§ {user}\n"
            f"   üìù {doc[:200]}...\n"
            f"   üìä –°—Ö–æ–∂–µ—Å—Ç—å: {similarity:.2f}\n"
        )
    
    await update.message.reply_text(
        "\n".join(response)[:4000],
        parse_mode="Markdown"
    )

async def delete_doc(update: Update, context):
    """–£–¥–∞–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ –µ–≥–æ ID"""
    doc_id = context.args[0] if context.args else None
    if not doc_id:
        await update.message.reply_text("–£–∫–∞–∂–∏—Ç–µ ID: /delete <id> (–Ω–∞–ø—Ä–∏–º–µ—Ä, /delete doc_123)")
        return
    
    collection.delete(ids=[doc_id])
    await update.message.reply_text(f"–î–æ–∫—É–º–µ–Ω—Ç {doc_id} —É–¥–∞–ª—ë–Ω")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")
    user = update.effective_user
    text = update.message.text

    if context.user_data.get("save_mode"):
        doc_id = f"doc_{user.id}_{datetime.now().timestamp()}"
        embedding = normalize_embedding(embedding_func([text])[0])
        norm = np.linalg.norm(embedding)
        #print(f"Norm of saved embedding for text '{text[:50]}...': {norm}")
        collection.add(
            documents=[text],
            embeddings=[embedding],
            ids=[doc_id],
            metadatas=[{
                "user": user.username if user.username else str(user.id),
                "source": "telegram",
                "timestamp": datetime.now().isoformat()
            }]
        )
        await update.message.reply_text("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ! –†–µ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–∫—Ç–∏–≤–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /save_off –¥–ª—è –≤—ã—Ö–æ–¥–∞.")
        return

    # Initialize conversation history
    if "conversation_history" not in context.user_data:
        context.user_data["conversation_history"] = []

    # Add current query to history
    context.user_data["conversation_history"].append({"role": "user", "content": text})
    # Limit history to 5 messages
    context.user_data["conversation_history"] = context.user_data["conversation_history"][-5:]

    query = await rephrase_query(text)
    
    query_embedding = normalize_embedding(embedding_func([query])[0])
    #norm = np.linalg.norm(query_embedding)
    #print(f"Norm of query embedding for '{query[:50]}...': {norm}")
    
    search_results = collection.query(
        query_embeddings=[query_embedding],
        n_results=15,
        include=["documents", "distances"]
    )

    if not search_results["distances"][0]:
        response = await llama_response(f"–í–æ–ø—Ä–æ—Å: {text}")
        context.user_data["conversation_history"].append({"role": "assistant", "content": response})
        await update.message.reply_text(response[:4000])
        return

    # Dynamic search logic
    scored_docs = sorted(
        [(1 - dist, doc) for doc, dist in zip(search_results["documents"][0], search_results["distances"][0])],
        key=lambda x: x[0], 
        reverse=True
    )

    max_similarity = scored_docs[0][0]
    dynamic_threshold = max(0.1, max_similarity - 0.1)

    context_parts = []
    total_length = 0
    MAX_CONTEXT_LENGTH = 3000
    total_docs = len(scored_docs)

    for similarity, doc in scored_docs:
        if similarity < dynamic_threshold:
            continue
        doc_length = len(doc)
        if total_length + doc_length > MAX_CONTEXT_LENGTH:
            remaining_space = MAX_CONTEXT_LENGTH - total_length
            if remaining_space > 50:
                context_parts.append(doc[:remaining_space])
            break
        context_parts.append(doc)
        total_length += doc_length

    context_text = "\n\n".join(context_parts)
    
    # Build prompt with conversation history
    history_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in context.user_data["conversation_history"][:-1]])
    prompt = (
        f"–ö–æ–Ω—Ç–µ–∫—Å—Ç (–æ—Ç–æ–±—Ä–∞–Ω–æ {len(context_parts)}/{total_docs} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, "
        f"–ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏: {dynamic_threshold:.2f}):\n{context_text}\n\n"
        f"–ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:\n{history_text}\n\n"
        f"–í–æ–ø—Ä–æ—Å: {text}\n\n"
        "–û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É, —É—á–∏—Ç—ã–≤–∞—è –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞, –∏–∑–±–µ–≥–∞—è –¥–æ–º—ã—Å–ª–æ–≤."
    )
    
    response = await llama_response(prompt)
    context.user_data["conversation_history"].append({"role": "assistant", "content": response})
    await update.message.reply_text(response[:4000])

def main():
    app = ApplicationBuilder().token(TOKEN).post_init(post_init).build()
    
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("save_on", save_mode_on))
    app.add_handler(CommandHandler("save_off", save_mode_off))
    app.add_handler(CommandHandler("search", search_docs))
    app.add_handler(CommandHandler("delete", delete_doc))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    print("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
    app.run_polling()

if __name__ == "__main__":
    print("=== –ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã ===")
    main()
    print("=== –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã ===")